{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d183680d-2a2a-4b52-bba2-420189a7c928",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install gymnasium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f62416fd-a5d5-4495-8fa7-ed45ee9971ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "\n",
    "import gymnasium as gym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1b24e050-d0f7-4109-8c63-daf334e3bfc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-16 21:21:26.080606: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-12-16 21:21:26.130539: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-12-16 21:21:26.131278: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-12-16 21:21:26.926210: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Change back to 1.0 epsilon\n"
     ]
    }
   ],
   "source": [
    "# Agent\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Dense, Input\n",
    "from keras.optimizers import Adam\n",
    "from collections import deque\n",
    "import gc\n",
    "\n",
    "print(\"Change back to 1.0 epsilon\")\n",
    "class DDQNAgent:\n",
    "    def __init__(self, state_size, action_size):\n",
    "        self.state_size = state_size\n",
    "        self.action_size = action_size\n",
    "\n",
    "        self.tau = 0.1\n",
    "        self.batch_size = 100\n",
    "        self.memory = deque(maxlen=10000)\n",
    "        self.gamma = 0.99\n",
    "        self.epsilon = 0.1\n",
    "        self.epsilon_min = 0.01\n",
    "        self.epsilon_decay = 0.99\n",
    "        self.learning_rate = 0.001\n",
    "        self.model = self.build_model()\n",
    "        self.target_model = self.build_model()\n",
    "        self.double_dqn = True\n",
    "\n",
    "    def build_model(self):\n",
    "        model = Sequential()\n",
    "        model.add(Dense(24, input_dim = self.state_size, activation='relu'))\n",
    "        model.add(Dense(24, activation='relu'))\n",
    "        \n",
    "        # model.add(Dense(128, input_dim = self.state_size, activation='relu'))\n",
    "        # model.add(Dense(64, activation='relu'))\n",
    "        # model.add(Dense(32, activation='relu'))\n",
    "        model.add(Dense(self.action_size, activation='relu'))\n",
    "        model.compile(loss='mse',optimizer=Adam(learning_rate=self.learning_rate))\n",
    "        return model\n",
    "\n",
    "    def remember(self, state, action, reward, next_state, done):\n",
    "        self.memory.append((state, action, reward, next_state, done))\n",
    "\n",
    "    def act(self, state):\n",
    "        # if self.epsilon > self.epsilon_min:\n",
    "        #     self.epsilon *= self.epsilon_decay\n",
    "        if np.random.rand() <= self.epsilon:\n",
    "            return random.randrange(self.action_size)\n",
    "        act_values = self.model.predict(state, verbose=0)\n",
    "        return np.argmax(act_values[0])\n",
    "\n",
    "    def sample(self, batch_size):\n",
    "        return random.sample(self.memory, batch_size)\n",
    "\n",
    "    def replay(self):\n",
    "        minibatch = self.sample(self.batch_size)\n",
    "        for state, action, reward, next_state, done in minibatch:\n",
    "            target = self.model.predict(state, verbose=0)\n",
    "            if not done:\n",
    "                # if self.double_dqn:\n",
    "                    predicted_action = np.argmax(target[0])#self.model.predict(next_state,verbose=0)[0])\n",
    "                    target_q = self.target_model.predict(next_state, verbose=0)[0][predicted_action]\n",
    "                    target[0][action] = reward + self.gamma * target_q\n",
    "                # else:\n",
    "                #     target_q = self.target_model.predict(next_state, verbose=0)[0]\n",
    "                #     target[0][action] = reward + self.gamma * max(target_q)\n",
    "            else:\n",
    "                target[0][action] = reward\n",
    "            self.model.fit(state,target, epochs=1, verbose=0)\n",
    "        if self.epsilon > self.epsilon_min:\n",
    "            self.epsilon *= self.epsilon_decay\n",
    "        gc.collect()\n",
    "\n",
    "    def update_target_model(self):\n",
    "        #TODO: Try training without a target network\n",
    "        weights = self.model.get_weights()\n",
    "        target_weights = self.target_model.get_weights()\n",
    "        for i in range(len(target_weights)):\n",
    "            target_weights[i] = weights[i] * self.tau + target_weights[i] * (1- self.tau)\n",
    "        self.target_model.set_weights(target_weights)\n",
    "\n",
    "    def save(self, file):\n",
    "        self.model.save_weights(file)\n",
    "\n",
    "    def load(self, file):\n",
    "        self.model.load_weights(file)\n",
    "        self.target_model.load_weights(file)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bc41420-302d-4902-8fb7-d519d8ebd776",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▌                                                     | 10/1000 [00:04<06:43,  2.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg game: 9.6, Epsilon: 0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|█                                                     | 20/1000 [00:24<09:46,  1.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg game: 9.6, Epsilon: 0.099\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|█▌                                                    | 30/1000 [00:44<10:21,  1.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg game: 9.9, Epsilon: 0.09801\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|██▏                                                   | 40/1000 [01:04<11:08,  1.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg game: 10.2, Epsilon: 0.0970299\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|██▋                                                   | 50/1000 [01:23<10:43,  1.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg game: 10.4, Epsilon: 0.096059601\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|███▏                                                  | 60/1000 [01:43<10:10,  1.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg game: 10.0, Epsilon: 0.09509900499\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|███▊                                                  | 70/1000 [02:02<09:47,  1.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg game: 10.0, Epsilon: 0.0941480149401\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|████▎                                                 | 80/1000 [02:20<08:35,  1.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg game: 9.1, Epsilon: 0.093206534790699\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|████▊                                                 | 90/1000 [02:38<09:55,  1.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg game: 9.9, Epsilon: 0.09227446944279201\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█████▎                                               | 100/1000 [02:56<09:10,  1.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg game: 9.7, Epsilon: 0.09135172474836409\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█████▊                                               | 110/1000 [03:15<09:53,  1.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg game: 9.8, Epsilon: 0.09043820750088044\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|██████▎                                              | 120/1000 [03:33<10:20,  1.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg game: 10.1, Epsilon: 0.08953382542587164\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|██████▉                                              | 130/1000 [03:53<12:28,  1.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg game: 9.5, Epsilon: 0.08863848717161292\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|███████▍                                             | 140/1000 [04:12<09:55,  1.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg game: 10.3, Epsilon: 0.08775210229989679\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|███████▉                                             | 150/1000 [04:30<08:59,  1.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg game: 9.8, Epsilon: 0.08687458127689782\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|████████▍                                            | 160/1000 [04:49<11:29,  1.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg game: 9.2, Epsilon: 0.08600583546412884\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█████████                                            | 170/1000 [05:07<10:51,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg game: 9.9, Epsilon: 0.08514577710948755\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█████████▌                                           | 180/1000 [05:26<10:02,  1.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg game: 9.7, Epsilon: 0.08429431933839267\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|██████████                                           | 190/1000 [05:44<12:50,  1.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg game: 9.8, Epsilon: 0.08345137614500873\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██████████▌                                          | 200/1000 [06:03<12:32,  1.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg game: 10.4, Epsilon: 0.08261686238355864\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|███████████▏                                         | 210/1000 [06:21<10:32,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg game: 10.1, Epsilon: 0.08179069375972306\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|███████████▋                                         | 220/1000 [06:40<10:43,  1.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg game: 9.8, Epsilon: 0.08097278682212583\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|████████████▏                                        | 230/1000 [07:00<13:02,  1.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg game: 10.2, Epsilon: 0.08016305895390458\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|████████████▋                                        | 240/1000 [07:23<12:53,  1.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg game: 10.2, Epsilon: 0.07936142836436554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|████████████▊                                        | 242/1000 [07:24<09:51,  1.28it/s]"
     ]
    }
   ],
   "source": [
    "# Train\n",
    "env = gym.make(\"CartPole-v1\")\n",
    "state_size_, action_size_ = 4, 2\n",
    "dqn_agent = DDQNAgent(state_size_, action_size_)\n",
    "try:\n",
    "    dqn_agent.load('cartpole.h5')\n",
    "except:\n",
    "    print(\"No previous model detected\")\n",
    "n_episodes = 1000\n",
    "n_steps = 200\n",
    "# capacity = 10000\n",
    "\n",
    "streak_step = 0\n",
    "total_step = 0\n",
    "\n",
    "save_episodes = 10\n",
    "for episode in tqdm(range(n_episodes)):\n",
    "    cur_state_, _ = env.reset()\n",
    "    for step in range(n_steps):\n",
    "        streak_step += 1\n",
    "        total_step += 1\n",
    "        cur_state_ = np.reshape(cur_state_, [1, state_size_])\n",
    "        action = dqn_agent.act(cur_state_)\n",
    "        observation, reward, done, _, _ = env.step(action)\n",
    "        observation = np.reshape(observation, [1, state_size_])\n",
    "        if done:\n",
    "            reward = -5\n",
    "        dqn_agent.remember(cur_state_, action, reward, observation, done)\n",
    "        if total_step % dqn_agent.batch_size == 0:\n",
    "            dqn_agent.replay()\n",
    "            dqn_agent.update_target_model()\n",
    "        cur_state_ = observation\n",
    "        if done:\n",
    "            break\n",
    "    if (episode + 1) % save_episodes == 0:\n",
    "        dqn_agent.save(\"cartpole.h5\")\n",
    "        print(f\"Avg game: {streak_step / save_episodes}, Epsilon: {dqn_agent.epsilon}\")\n",
    "        streak_step = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efb81c8b-9aa3-4e32-9e28-8496dfb0a66e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Doesn't render in jupyter\n",
    "# obs = env.reset()\n",
    "# done = False\n",
    "# while not done:\n",
    "#     action = dqn_agent.act(obs)\n",
    "#     obs, rewards, done, _, _ = env.step(action)\n",
    "#     env.render()\n",
    "# env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a8a2117-5114-4994-b7d6-306ca592bc4b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
