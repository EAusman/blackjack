{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d183680d-2a2a-4b52-bba2-420189a7c928",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install gymnasium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f62416fd-a5d5-4495-8fa7-ed45ee9971ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "\n",
    "import gymnasium as gym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1b24e050-d0f7-4109-8c63-daf334e3bfc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agent\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Dense, Input\n",
    "from keras.optimizers import Adam\n",
    "from collections import deque\n",
    "\n",
    "class DDQNAgent:\n",
    "    def __init__(self, state_size, action_size):\n",
    "        self.state_size = state_size\n",
    "        self.action_size = action_size\n",
    "\n",
    "        self.tau = 0.01\n",
    "        self.batch_size = 64\n",
    "        self.memory = deque(maxlen=10000)\n",
    "        self.gamma = 0.95\n",
    "        self.epsilon = 1.0\n",
    "        self.epsilon_min = 0.01\n",
    "        self.epsilon_decay = 0.995\n",
    "        self.leaning_rate = 0.001\n",
    "        self.model = self.build_model()\n",
    "        self.target_model = self.build_model()\n",
    "\n",
    "    def build_model(self):\n",
    "        model = Sequential()\n",
    "        model.add(Dense(128, input_dim = self.state_size, activation='relu'))\n",
    "        model.add(Dense(64, activation='relu'))\n",
    "        model.add(Dense(32, activation='relu'))\n",
    "        model.add(Dense(self.action_size, activation='relu'))\n",
    "        model.compile(loss='mse',optimizer='adam')\n",
    "        return model\n",
    "\n",
    "    def remember(self, state, action, reward, next_state, done):\n",
    "        self.memory.append((state, action, reward, next_state, done))\n",
    "\n",
    "    def act(self, state):\n",
    "        if np.random.rand() <= self.epsilon:\n",
    "            return random.randrange(self.action_size)\n",
    "        act_values = self.model.predict(state, verbose=0)\n",
    "        return np.argmax(act_values[0])\n",
    "\n",
    "    def sample(self, batch_size):\n",
    "        return random.sample(self.memory, batch_size)\n",
    "\n",
    "    def replay(self):\n",
    "        minibatch = self.sample(self.batch_size)\n",
    "        for state, action, reward, next_state, done in minibatch:\n",
    "            target = reward\n",
    "            if not done:\n",
    "                predicted_action = np.argmax(self.model.predict(next_state,verbose=0)[0])\n",
    "                target = reward + self.gamma * self.target_model.predict(next_state, verbose=0)[0][predicted_action]\n",
    "            target_f = self.model.predict(state, verbose=0)\n",
    "            target_f[0][action] = target\n",
    "            self.model.fit(state,target_f, epochs=1, verbose=0)\n",
    "        if self.epsilon > self.epsilon_min:\n",
    "            self.epsilon *= self.epsilon_decay\n",
    "\n",
    "    def update_target_model(self):\n",
    "        weights = self.model.get_weights()\n",
    "        target_weights = self.target_model.get_weights()\n",
    "        for i in range(len(target_weights)):\n",
    "            target_weights[i] = weights[i] * self.tau + target_weights[i] * (1- self.tau)\n",
    "        self.target_model.set_weights(target_weights)\n",
    "\n",
    "    def save(self, file):\n",
    "        self.model.save_weights(file)\n",
    "\n",
    "    def load(self, file):\n",
    "        self.model.load_weights(file)\n",
    "        self.target_model.load_weights(file)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6bc41420-302d-4902-8fb7-d519d8ebd776",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg game: 2.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|███████████████                                                                                                                                        | 10/100 [00:28<04:32,  3.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg game: 19.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|████████████████████████████▋                                                                                                                          | 19/100 [00:56<04:06,  3.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg game: 21.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|███████████████████████████████████████████▊                                                                                                           | 29/100 [01:23<03:16,  2.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg game: 18.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|███████████████████████████████████████████████████████████████▍                                                                                       | 42/100 [01:51<02:03,  2.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg game: 19.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████████████████████████████████████████████████████████████████████████████                                                                          | 51/100 [02:28<02:35,  3.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg game: 27.9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████████████████████████████████████████████████████████████████████████████████████████▌                                                            | 60/100 [02:57<01:50,  2.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg game: 18.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                              | 69/100 [03:33<01:49,  3.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg game: 27.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                            | 81/100 [04:01<00:39,  2.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg game: 18.7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍          | 93/100 [04:38<00:15,  2.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg game: 21.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [04:57<00:00,  2.98s/it]\n"
     ]
    }
   ],
   "source": [
    "# Train\n",
    "env = gym.make(\"CartPole-v1\")\n",
    "state_size_, action_size_ = 4, 2\n",
    "dqn_agent = DDQNAgent(state_size_, action_size_)\n",
    "try:\n",
    "    dqn_agent.load('cartpole.h5')\n",
    "except:\n",
    "    print(\"No previous model detected\")\n",
    "n_episodes = 100\n",
    "n_steps = 200\n",
    "capacity = 10000\n",
    "\n",
    "streak_step = 0\n",
    "total_step = 0\n",
    "\n",
    "save_episodes = 10\n",
    "for episode in tqdm(range(n_episodes)):\n",
    "    cur_state_, _ = env.reset()\n",
    "    for step in range(n_steps):\n",
    "        streak_step += 1\n",
    "        total_step += 1\n",
    "        cur_state_ = np.reshape(cur_state_, [1, state_size_])\n",
    "        action = dqn_agent.act(cur_state_)\n",
    "        observation, reward, done, _, _ = env.step(action)\n",
    "        observation = np.reshape(observation, [1, state_size_])\n",
    "        dqn_agent.remember(cur_state_, action, reward, observation, done)\n",
    "        if total_step % dqn_agent.batch_size == 0:\n",
    "            dqn_agent.replay()\n",
    "            dqn_agent.update_target_model()\n",
    "        cur_state_ = observation\n",
    "        if done:\n",
    "            break\n",
    "    if episode % save_episodes == 0:\n",
    "        dqn_agent.save(\"cartpole.h5\")\n",
    "        print(f\"Avg game: {streak_step / save_episodes}\")\n",
    "        streak_step = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "efb81c8b-9aa3-4e32-9e28-8496dfb0a66e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Doesn't render in jupyter\n",
    "obs = env.reset()\n",
    "done = False\n",
    "while not done:\n",
    "    action = dqn_agent.act(obs)\n",
    "    obs, rewards, done, _, _ = env.step(action)\n",
    "    env.render()\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a8a2117-5114-4994-b7d6-306ca592bc4b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
